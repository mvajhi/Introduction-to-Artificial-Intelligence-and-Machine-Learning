{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "eY99YE-VG1C9",
      "metadata": {
        "id": "eY99YE-VG1C9"
      },
      "source": [
        "# Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fec65989e04597f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fec65989e04597f0",
        "outputId": "3d019598-09fb-472b-d1e0-8df84cef855e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install gensim emoji nltk tqdm seaborn torch torchsummary -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "id": "initial_id"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# import gensim\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "import os\n",
        "\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf946d026ed2d98e",
      "metadata": {
        "collapsed": false,
        "id": "cf946d026ed2d98e"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e83a8b72b644c2",
      "metadata": {
        "collapsed": false,
        "id": "3e83a8b72b644c2"
      },
      "source": [
        "## Model training config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2d0826c5b8eb52c9",
      "metadata": {
        "id": "2d0826c5b8eb52c9"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = 4e-4\n",
        "WEIGHT_DECAY = 1e-2\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 15\n",
        "\n",
        "SEQUENCE_LEN = 64\n",
        "CNN_FILTERS = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b1f939dd5898a0b6",
      "metadata": {
        "id": "b1f939dd5898a0b6"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27110752c038c1d0",
      "metadata": {
        "collapsed": false,
        "id": "27110752c038c1d0"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32b050729991fec9",
      "metadata": {
        "collapsed": false,
        "id": "32b050729991fec9"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "88e92f34d72c6f62",
      "metadata": {
        "id": "88e92f34d72c6f62"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>intention</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>my life is meaningless i just want to end my l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>muttering i wanna die to myself daily for a fe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>work slave i really feel like my only purpose ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i did something on the 2 of october i overdose...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i feel like no one cares i just want to die ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9114</th>\n",
              "      <td>have you ever laid on your bed at night and cr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9115</th>\n",
              "      <td>the fault the blame the pain s still there i m...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9116</th>\n",
              "      <td>stop asking me to trust you when i m still cou...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9117</th>\n",
              "      <td>i never know how to handle sadness crying make...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9118</th>\n",
              "      <td>when cancer takes a life we blame cancer depre...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9119 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  tweet  intention\n",
              "0     my life is meaningless i just want to end my l...          1\n",
              "1     muttering i wanna die to myself daily for a fe...          1\n",
              "2     work slave i really feel like my only purpose ...          1\n",
              "3     i did something on the 2 of october i overdose...          1\n",
              "4     i feel like no one cares i just want to die ma...          1\n",
              "...                                                 ...        ...\n",
              "9114  have you ever laid on your bed at night and cr...          1\n",
              "9115  the fault the blame the pain s still there i m...          1\n",
              "9116  stop asking me to trust you when i m still cou...          1\n",
              "9117  i never know how to handle sadness crying make...          1\n",
              "9118  when cancer takes a life we blame cancer depre...          1\n",
              "\n",
              "[9119 rows x 2 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('data.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57f7552c58ea498e",
      "metadata": {
        "collapsed": false,
        "id": "57f7552c58ea498e"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f16efd0184e90f40",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f16efd0184e90f40",
        "outputId": "44e62e18-a7ba-4ce1-8bf6-0ec77ca51205"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/codespace/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /home/codespace/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /home/codespace/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "import emoji\n",
        "import re\n",
        "import string\n",
        "\n",
        "nltk.download([\"stopwords\", \"punkt\", \"wordnet\", \"averaged_perceptron_tagger\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "dbe50f445aa09ecc",
      "metadata": {
        "id": "dbe50f445aa09ecc"
      },
      "outputs": [],
      "source": [
        "def convert_emoji_to_text(text):\n",
        "    \"\"\"This function would replace emojies with a space\"\"\"\n",
        "    return emoji.demojize(text)\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def nltk_pos_tagger(nltk_tag):\n",
        "    if nltk_tag.startswith('J'):\n",
        "        return 'a'\n",
        "    elif nltk_tag.startswith('V'):\n",
        "        return 'v'\n",
        "    elif nltk_tag.startswith('N'):\n",
        "        return 'n'\n",
        "    elif nltk_tag.startswith('R'):\n",
        "        return 'r'\n",
        "    else:\n",
        "        return 'n'\n",
        "\n",
        "def preprocess_data(text: str):\n",
        "    \"\"\"\n",
        "    Preprocessing steps are as follows:\n",
        "    1. lowercase the text\n",
        "    2. remove punctuation\n",
        "    3. remove numbers\n",
        "    4. remove urls\n",
        "    5. remove usernames\n",
        "    6. remove extra spaces\n",
        "    7. convert emojis to text\n",
        "    8. remove non-word characters\n",
        "    9. lemmatization and tokenization of the text\n",
        "    10. remove stopwords\n",
        "    :param text: str\n",
        "    :return: tokens: list[str]\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: lowercase the text\n",
        "    text = text.lower()\n",
        "\n",
        "    # TODO: remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # TODO: remove numbers\n",
        "    text = text.translate(str.maketrans('', '', string.digits))\n",
        "\n",
        "    # TODO: remove urls,\n",
        "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
        "\n",
        "    # TODO: remove usernames\n",
        "    text = re.sub(r'@\\S+', '', text)\n",
        "\n",
        "    # TODO: remove extra spaces\n",
        "    text = re.sub(' +', ' ', text)\n",
        "\n",
        "    # TODO: convert emojis to text\n",
        "    text = convert_emoji_to_text(text)\n",
        "\n",
        "    # TODO: remove non-word characters\n",
        "    text = re.sub(r'[^a-z ]+', '', text)\n",
        "\n",
        "    # TODO: lemmatization and tokenization of the text\n",
        "    tokens = [nltk.WordNetLemmatizer().lemmatize(word) for word in nltk.word_tokenize(text)]\n",
        "\n",
        "    # TODO: remove stopwords\n",
        "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    return tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "11ac7d394e03d9f",
      "metadata": {
        "id": "11ac7d394e03d9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'my life is meaningless i just want to end my life so badly my life is completely empty and i dont want to have to create meaning in it creating meaning is pain how long will i hold back the urge to run my car head first into the next person coming the opposite way when will i stop feeling jealous of tragic characters like gomer pile for the swift end they were able to bring to their lives'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'life meaningless want end life badly life completely empty dont want create meaning creating meaning pain long hold back urge run car head first next person coming opposite way stop feeling jealous tragic character like gomer pile swift end able bring life'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'muttering i wanna die to myself daily for a few months now i feel worthless shes my soulmate i cant live in this horrible world without her i am so lonely i wish i could just turn off the part of my brain that feels '"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'muttering wan na die daily month feel worthless shes soulmate cant live horrible world without lonely wish could turn part brain feel'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## TODO: Show some samples before/after preprocessing\n",
        "display(df.iloc[0].tweet, ' '.join(preprocess_data(df.iloc[0].tweet)))\n",
        "display(df.iloc[1].tweet, ' '.join(preprocess_data(df.iloc[1].tweet)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e129c7a31663741",
      "metadata": {
        "collapsed": false,
        "id": "2e129c7a31663741"
      },
      "source": [
        "# Word2Vec - Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8d15b31459fd1e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d15b31459fd1e5",
        "outputId": "76a14c70-c496-4f53-b1f1-9f7626a0f9a4"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'triu' from 'scipy.linalg' (/home/codespace/.local/lib/python3.10/site-packages/scipy/linalg/__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# print available word2vec models\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloader\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mapi\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(api\u001b[38;5;241m.\u001b[39minfo()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys()))\n",
            "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/gensim/__init__.py:11\u001b[0m\n\u001b[1;32m      7\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4.3.2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m     14\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgensim\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mhandlers:  \u001b[38;5;66;03m# To ensure reload() doesn't add another one\u001b[39;00m\n",
            "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/gensim/corpora/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThis package contains implementations of various streaming corpus I/O format.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# bring corpus classes directly into package namespace, to save some typing\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexedcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IndexedCorpus  \u001b[38;5;66;03m# noqa:F401 must appear before the other classes\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmmcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MmCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbleicorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BleiCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n",
            "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/gensim/corpora/indexedcorpus.py:14\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interfaces, utils\n\u001b[1;32m     16\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIndexedCorpus\u001b[39;00m(interfaces\u001b[38;5;241m.\u001b[39mCorpusABC):\n",
            "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/gensim/interfaces.py:19\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"Basic interfaces used across the whole Gensim package.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03mThese interfaces are used for building corpora, model transformation and similarity queries.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils, matutils\n\u001b[1;32m     22\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCorpusABC\u001b[39;00m(utils\u001b[38;5;241m.\u001b[39mSaveLoad):\n",
            "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/gensim/matutils.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m entropy\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_blas_funcs, triu\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlapack\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_lapack_funcs\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m psi  \u001b[38;5;66;03m# gamma function utils\u001b[39;00m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'triu' from 'scipy.linalg' (/home/codespace/.local/lib/python3.10/site-packages/scipy/linalg/__init__.py)"
          ]
        }
      ],
      "source": [
        "# print available word2vec models\n",
        "import gensim.downloader as api\n",
        "print(\"\\n\".join(api.info()['models'].keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55bbe6faa1226b8d",
      "metadata": {
        "id": "55bbe6faa1226b8d"
      },
      "outputs": [],
      "source": [
        "W2V_PATH = None # Path to W2V if downloaded\n",
        "if W2V_PATH is not None and os.path.exists(W2V_PATH):\n",
        "    print(\"Loading Word2Vec model...\")\n",
        "    w2v_model = gensim.models.KeyedVectors.load(W2V_PATH, mmap='r')\n",
        "    print(\"Word2Vec model is loaded.\")\n",
        "else:\n",
        "    print(\"Downloading Word2Vec model...\")\n",
        "    w2v_model = api.load(\"word2vec-google-news-300\")\n",
        "    print(\"Word2vec model is downloaded.\")\n",
        "    if W2V_PATH is not None:\n",
        "      print(\"\\nSaving Word2Vec model...\")\n",
        "      w2v_model.save(W2V_PATH)\n",
        "      print(\"Word2Vec model is saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d53926889defc38",
      "metadata": {
        "id": "7d53926889defc38"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_VECTOR_DIM = w2v_model.vector_size"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21730f8dd01e5b4e",
      "metadata": {
        "collapsed": false,
        "id": "21730f8dd01e5b4e"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xdqLYrA4xjuX",
      "metadata": {
        "id": "xdqLYrA4xjuX"
      },
      "outputs": [],
      "source": [
        "class Twitter(Dataset):\n",
        "    def __init__(self, dataframe: pd.DataFrame, w2v_model: gensim.models.KeyedVectors, sequence_len: int):\n",
        "        self.dataframe = dataframe\n",
        "        self.w2v_model = w2v_model\n",
        "        self.max_sequence_len = sequence_len\n",
        "        self.vector_size = w2v_model.vector_size\n",
        "\n",
        "        self.df_token_col = \"tokens\"\n",
        "\n",
        "\n",
        "        self._proc_dataset()\n",
        "\n",
        "        self.len = len(self.dataframe)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.dataframe.iloc[idx][\"vector\"], self.dataframe.iloc[idx][\"intention\"]\n",
        "\n",
        "    def get_vector_size(self):\n",
        "        return self.vector_size\n",
        "\n",
        "    def _proc_dataset(self):\n",
        "        # Preprocess and return tokens list\n",
        "        self.dataframe[self.df_token_col] = self.dataframe[\"tweet\"].map(preprocess_data)\n",
        "\n",
        "        # delete samples with empty tokens\n",
        "        lwz = len(self.dataframe)\n",
        "        self.dataframe = self.dataframe[self.dataframe[self.df_token_col].map(len) > 0]\n",
        "        self.dataframe.reset_index(drop=True, inplace=True)\n",
        "        print(f\"Deleted 0-Len Samples: {lwz - len(self.dataframe)}\")\n",
        "\n",
        "        # Add padding\n",
        "        self.dataframe[self.df_token_col] = self.dataframe[self.df_token_col].map(self._pad)\n",
        "\n",
        "        # Get embedding's vectors\n",
        "        self.dataframe[\"vector\"] = self.dataframe[self.df_token_col].map(self._get_word_vectors)\n",
        "\n",
        "    def _get_word_vectors(self, tokens: list) -> torch.tensor:\n",
        "      # TODO: Return a 2D tensor for whole list of tokens, using vectors from w2v as explained on the description\n",
        "\n",
        "\n",
        "    def _pad(self, tokens: list):\n",
        "        # TODO: Add paddings (zero-vectors) into the end of sequence to reach the desired length\n",
        "\n",
        "    def seq_report(self):\n",
        "        length_all = self.dataframe[self.df_token_col].map(len).tolist()\n",
        "        max_length = np.max(length_all)\n",
        "        print(f\"Sequence Length Report\")\n",
        "        print(f\":::::MAX  LENGTH:::[{max_length:^5}]\")\n",
        "        print(f\":::::MIN  LENGTH:::[{np.min(length_all):^5}]\")\n",
        "        print(f\":::::MEAN LENGTH:::[{np.mean(length_all):^5}]\")\n",
        "\n",
        "        all_tokens = set()\n",
        "        for token_set in self.dataframe[self.df_token_col].tolist():\n",
        "            all_tokens = all_tokens.union(set(token_set))\n",
        "        unique_tokens_count = len(all_tokens)\n",
        "        valid_tokens = sum(1 if token in self.w2v_model else 0 for token in all_tokens)\n",
        "        print(\"Sequence Tokenization Report\")\n",
        "        print(f\":::::All Unique Tokens:::[{unique_tokens_count:^6}\")\n",
        "        print(f\":::::All Valid Tokens:::[{valid_tokens:^6}\")\n",
        "        print(f\":::::Valid Tokens:::[{round(100*valid_tokens/unique_tokens_count, 2):^5}%]\")\n",
        "\n",
        "    @staticmethod\n",
        "    def _to_tensor(tokens: list):\n",
        "        return torch.tensor(tokens, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b87e7e8b267a1c8",
      "metadata": {
        "collapsed": false,
        "id": "4b87e7e8b267a1c8"
      },
      "source": [
        "# Prepare Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd00ab880892e646",
      "metadata": {
        "collapsed": false,
        "id": "bd00ab880892e646"
      },
      "source": [
        "## Split Data into train-valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a54facda2729872",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a54facda2729872",
        "outputId": "970c41d9-1af0-4892-c42d-2fee01e1a0ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TODO: Split dataset into train-test split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "670fcd8db0e5651c",
      "metadata": {
        "collapsed": false,
        "id": "670fcd8db0e5651c"
      },
      "source": [
        "## Create Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e4a5b690afadad5",
      "metadata": {
        "id": "3e4a5b690afadad5"
      },
      "outputs": [],
      "source": [
        "# TODO: create twitter dataset\n",
        "train_dataset = Twitter(\n",
        "    ...\n",
        ")\n",
        "valid_dataset = Twitter(\n",
        "    ...\n",
        ")\n",
        "\n",
        "print(f\"Train dataset length: {len(train_dataset)}\")\n",
        "print(f\"Valid dataset length: {len(valid_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd1da733e79676ff",
      "metadata": {
        "collapsed": false,
        "id": "fd1da733e79676ff"
      },
      "source": [
        "# Model and Train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa29012e257e3d9",
      "metadata": {
        "collapsed": false,
        "id": "aa29012e257e3d9"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5b33657ae501516",
      "metadata": {
        "id": "d5b33657ae501516"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def model_eval(model, loader, loss_function, device: str['cuda', 'cpu', 'auto']):\n",
        "    \"\"\"Returns test_loss, test_acc\"\"\"\n",
        "    test_loss = 0.0\n",
        "    test_acc = 0.0\n",
        "\n",
        "    if device == \"auto\":\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = model.to(device)\n",
        "    itr = tqdm(loader, total=len(loader), leave=False)\n",
        "\n",
        "    for inputs, labels in itr:\n",
        "        # TODO: move model's inputs to `device`\n",
        "\n",
        "        # TODO: use model's forward pass to generate outputs\n",
        "\n",
        "        # TODO: calculate model's loss\n",
        "        # loss =\n",
        "\n",
        "        # TODO: calculate/update model's accuracy\n",
        "\n",
        "        itr.set_description(\"(Eval)\")\n",
        "        itr.set_postfix(\n",
        "            loss=round(loss.item(), 5),\n",
        "            accuracy=round(test_acc, 5),\n",
        "        )\n",
        "\n",
        "    return test_loss, test_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bc1edee98f616b5",
      "metadata": {
        "id": "1bc1edee98f616b5"
      },
      "outputs": [],
      "source": [
        "def train_model(\n",
        "        model,\n",
        "        batch_size,\n",
        "        loss_function,\n",
        "        optimizer,\n",
        "        epochs,\n",
        "        train_set,\n",
        "        valid_set,\n",
        "        device: str['cuda', 'cpu', 'auto'],\n",
        "):\n",
        "\n",
        "    if device == \"auto\":\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    train_losses = []\n",
        "    train_accs = []\n",
        "\n",
        "    valid_losses = []\n",
        "    valid_accs = []\n",
        "\n",
        "    # TODO: create dataloaders from datasets\n",
        "    # train_loader =\n",
        "    # valid_loader =\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    itr = tqdm(train_loader, total=len(train_loader), leave=False)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        epoch_acc = 0\n",
        "        for idx, (inputs, labels) in enumerate(itr, start=1):\n",
        "            # TODO: move model's inputs to `device`\n",
        "\n",
        "            # TODO: use model's forward pass to generate outputs\n",
        "\n",
        "            # TODO: process model's predictipns and calculate/update accuracy\n",
        "\n",
        "            # TODO: calculate model's loss and update epoch's loss\n",
        "            # loss =\n",
        "\n",
        "            # TODO: 1. clear optimizer's state and zero prev grads,\n",
        "            # TODO: 2. backward calculated loss\n",
        "            # TODO: 3. step optimizer\n",
        "\n",
        "            itr.set_description(f\"(Training) Epoch [{epoch + 1}/{epochs}]\")\n",
        "            itr.set_postfix(\n",
        "              loss=round(loss.item(), 5),\n",
        "              accuracy=round(epoch_acc, 5),\n",
        "              )\n",
        "\n",
        "        model.eval()\n",
        "        valid_loss, valid_acc = model_eval(\n",
        "            model=model,\n",
        "            loader=valid_loader,\n",
        "            loss_function=loss_function,\n",
        "            device=device\n",
        "            )\n",
        "\n",
        "        # TODO: update statistics regaurding model's loss and acc in training or validation phases\n",
        "\n",
        "    history = {\n",
        "      \"train_loss\": train_losses,\n",
        "      \"train_acc\": train_accs,\n",
        "\n",
        "      \"valid_loss\": valid_losses,\n",
        "      \"valid_acc\": valid_accs,\n",
        "    }\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e5acc20a7d5d446",
      "metadata": {
        "id": "6e5acc20a7d5d446"
      },
      "outputs": [],
      "source": [
        "def trend_plot_helper(pobj):\n",
        "    plt.figure(figsize=(5*len(pobj), 5))\n",
        "    for idx, (titler, plots) in enumerate(pobj.items(), start=1):\n",
        "        plt.subplot(1, len(pobj), idx)\n",
        "        for label, trend in plots:\n",
        "            plt.plot(range(1, len(trend)+1), trend, label=label)\n",
        "        yt, xt = titler.split(' - ')\n",
        "        plt.xlabel(xt)\n",
        "        plt.ylabel(yt)\n",
        "        plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "819f88c36492de48",
      "metadata": {
        "id": "819f88c36492de48"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def generate_confusion_matrix(model, dataset, device='auto'):\n",
        "    if device == 'auto':\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "    itr = tqdm(loader, leave=False, desc=\"Generate data\")\n",
        "\n",
        "    # TODO: code here, you must fill variables below\n",
        "    # TODO: labels = true labels from the dataset\n",
        "    # TODO: predicted = labels predicted by the model\n",
        "\n",
        "    cm = metrics.confusion_matrix(\n",
        "        y_true=labels,\n",
        "        y_pred=predicted,\n",
        "    )\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "    sns.heatmap(cm, cmap='Blues', annot=True, cbar=False, fmt=\".0f\",)\n",
        "    plt.xlabel('Predicted Label', labelpad=20)\n",
        "    plt.ylabel('True Label', labelpad=20)\n",
        "    plt.title('Confusion Matrix', fontsize=30)\n",
        "\n",
        "    recall = metrics.recall_score(y_true=labels, y_pred=predicted, average='macro')\n",
        "    f1 = metrics.f1_score(y_true=labels, y_pred=predicted, average='macro')\n",
        "    precision = metrics.precision_score(y_true=labels, y_pred=predicted, average='macro')\n",
        "    report = metrics.classification_report(y_true=labels, y_pred=predicted)\n",
        "\n",
        "    return {'recall': recall, 'f1': f1, 'precision': precision, 'report': report}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1566b2a8428318c8",
      "metadata": {
        "collapsed": false,
        "id": "1566b2a8428318c8"
      },
      "source": [
        "## Model's Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2ed27ccf8d0307c",
      "metadata": {
        "id": "a2ed27ccf8d0307c"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self): # TODO: define your args here\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # TODO: define you network's layers here\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # TODO: implement forward pass here\n",
        "\n",
        "        # return"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-XhOZ_qwF6Bh",
      "metadata": {
        "id": "-XhOZ_qwF6Bh"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76d30ba6554b6c48",
      "metadata": {
        "id": "76d30ba6554b6c48"
      },
      "outputs": [],
      "source": [
        "# TODO: instantiate your model here\n",
        "# model ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a57ddcb0836683ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a57ddcb0836683ec",
        "outputId": "0695a446-bb1b-49cc-8eaf-b059c477d173"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
        "cnn_model_train_history = train_model( # TODO: train your model\n",
        "    ...\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac375ced89f224ce",
      "metadata": {
        "id": "ac375ced89f224ce"
      },
      "outputs": [],
      "source": [
        "trend_plot_helper(\n",
        "    {\n",
        "        \"Accuracy - Epoch\": [\n",
        "            (\"Train Acc\", cnn_model_train_history[\"train_acc\"]),\n",
        "            (\"Validation Acc\", cnn_model_train_history[\"valid_acc\"]),\n",
        "        ],\n",
        "        \"Loss - Epoch\": [\n",
        "            (\"Train Loss\", cnn_model_train_history[\"train_loss\"]),\n",
        "            (\"Validation Loss\", cnn_model_train_history[\"valid_loss\"])\n",
        "        ]\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a09473d5783fa70f",
      "metadata": {
        "id": "a09473d5783fa70f"
      },
      "outputs": [],
      "source": [
        "cnn_model_report = generate_confusion_matrix(\n",
        "    model=cnn_model,\n",
        "    dataset=valid_dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ee01e4607601dd8",
      "metadata": {
        "id": "8ee01e4607601dd8"
      },
      "outputs": [],
      "source": [
        "print(f\"Recall:    {cnn_model_report['recall']:.3f}\")\n",
        "print(f\"F1:        {cnn_model_report['f1']:.3f}\")\n",
        "print(f\"Precision: {cnn_model_report['precision']:.3f}\")\n",
        "print(cnn_model_report['report'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "eY99YE-VG1C9",
        "cf946d026ed2d98e",
        "27110752c038c1d0",
        "2e129c7a31663741",
        "21730f8dd01e5b4e",
        "4b87e7e8b267a1c8",
        "bd00ab880892e646",
        "670fcd8db0e5651c"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
